{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_scipy_stats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3NMadPK9cPae+YuzndNTm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2021/blob/master/07_scipy_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqAIqBlSmD4w"
      },
      "source": [
        "#Statistics in Python\n",
        "\n",
        "sources:\n",
        "\n",
        "https://medium.com/insights-school/learn-basic-statistics-with-python-cc0f45275929\n",
        "\n",
        "https://scipy-lectures.org/intro/scipy.html#scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86WqXweTk9Jh"
      },
      "source": [
        "import math\n",
        "import statistics\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTTVyKXslupX"
      },
      "source": [
        "# Measures of Central Tendency\n",
        "The measures of central tendency show the central or middle values of datasets. There are several definitions of what’s considered to be the center of a dataset. In this tutorial, you’ll learn how to identify and calculate these measures of central tendency:\n",
        "\n",
        "## Mean\n",
        "The sample mean, also called the sample arithmetic mean or simply the average, is the arithmetic average of all the items in a dataset. You can calculate the mean with pure Python using sum() and len(), without importing libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LnbFPQplR--"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "mean = sum(x) / len(x)\n",
        "print (mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DDg71BHlZ_I"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "mean = np.mean(x)\n",
        "print (mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbCghBSyldvN"
      },
      "source": [
        "x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0]\n",
        "mean = np.nanmean(x_with_nan)\n",
        "print (mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS88kTWll_Qw"
      },
      "source": [
        "## Weighted Mean\n",
        "The weighted mean, also called the weighted arithmetic mean or weighted average, is a generalization of the arithmetic mean that enables you to define the relative contribution of each data point to the result.\n",
        "The weighted mean is very handy when you need the mean of a dataset containing items that occur with given relative frequencies.\n",
        "For example, say that you have a set in which 20% of all items are equal to 2, 50% of the items are equal to 4, and the remaining 30% of the items are equal to 8. You can calculate the mean of such a set like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZqCpAWpls1t"
      },
      "source": [
        "x = [2,4, 8]\n",
        "w = [0.2, 0.5, 0.3]\n",
        "weighted_mean = np.average(x, weights=w)\n",
        "print (weighted_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svQtQ0aEmgWU"
      },
      "source": [
        "## Median\n",
        "The sample median is the middle element of a sorted dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU89gVremmSl"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "median = np.median(x)\n",
        "print (median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Xgz37umnM5"
      },
      "source": [
        "x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0]\n",
        "median= np.nanmedian(x_with_nan)\n",
        "print (median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDzxAsrumtqT"
      },
      "source": [
        "# Measures of Variability\n",
        "The measures of central tendency aren’t sufficient to describe data. You’ll also need the measures of variability that quantify the spread of data points.\n",
        "## Variance\n",
        "The sample variance quantifies the spread of the data. It shows numerically how far the data points are from the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNv4Ej79mp24"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "mean = statistics.mean(x)\n",
        "variance = statistics.variance(x,mean)\n",
        "print (mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjPNH665mz9W"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "mean = statistics.mean(x)\n",
        "variance = statistics.variance(x,mean)\n",
        "standard_deviation = variance ** 0.5\n",
        "print (standard_deviation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb7KAv_zm2_C"
      },
      "source": [
        "## Standard Deviation\n",
        "The sample standard deviation is another measure of data spread. The standard deviation is often more convenient than the variance because it has the same unit as the data points. Once you get the variance, you can calculate the standard deviation with pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S47vO1HnJfET"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "mean = statistics.mean(x)\n",
        "variance = statistics.variance(x,mean)\n",
        "standard_deviation = variance ** 0.5\n",
        "print (standard_deviation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3CuEFKTJfwp"
      },
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "standard_deviation = statistics.stdev(x)\n",
        "print (standard_deviation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbCvXLHEJsnn"
      },
      "source": [
        "# Percentiles\n",
        "Percentiles are used in statistics to give you a number that describes the value that a given percent of the values are lower than.\n",
        "Example: Let’s say we have an array of the ages of all the people that lives in a street."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43YBIOfQJoJF"
      },
      "source": [
        "ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
        "ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
        "x = np.percentile(ages, 75)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH--LP6vJ1X2"
      },
      "source": [
        "x = np.percentile(ages, [25,50,75])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXXSkIAxJ-I1"
      },
      "source": [
        "# Summary of Descriptive Statistics\n",
        "SciPy and Pandas offer useful routines to quickly get descriptive statistics with a single function or method call. You can use scipy.stats.describe() like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfqevoM7J4zV"
      },
      "source": [
        "x = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
        "result = stats.describe(x, ddof=1, bias=False)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrbOmlgNJ9RB"
      },
      "source": [
        "x = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
        "z = pd.Series(x)\n",
        "result = z.describe()\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsiq8VcRZdYr"
      },
      "source": [
        "data = pd.read_csv('https://scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values=\".\")\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omW7sC3XaFig"
      },
      "source": [
        "data.shape  \n",
        "data.columns\n",
        "print(data['Gender'])  # Columns can be addressed by name   \n",
        "# Simpler selector\n",
        "data[data['Gender'] == 'Female']['VIQ'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnKDuHCOaKzu"
      },
      "source": [
        "groupby_gender = data.groupby('Gender')\n",
        "for gender, value in groupby_gender['VIQ']:\n",
        "    print((gender, value.mean()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhXnWIskaZtD"
      },
      "source": [
        "# try to use a list comprehension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UypDI8NcaQay"
      },
      "source": [
        "groupby_gender.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHskC55qZ190"
      },
      "source": [
        "# Hypothesis testing: comparing two groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVaeENVgarVN"
      },
      "source": [
        "## Student’s t-test: the simplest statistical test\n",
        "### 1-sample t-test: testing the value of a population mean\n",
        "scipy.stats.ttest_1samp() tests if the population mean of data is likely to be equal to a given value (technically if observations are drawn from a Gaussian distributions of given population mean). It returns the T statistic, and the p-value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZY0mNpzb_YR"
      },
      "source": [
        "stats.ttest_1samp(data['VIQ'], 0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWNrJWvlb4nY"
      },
      "source": [
        "## 2-sample t-test: testing for difference across populations\n",
        "We have seen above that the mean VIQ in the male and female populations were different. To test if this is significant, we do a 2-sample t-test with scipy.stats.ttest_ind():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSeXznL6a3wq"
      },
      "source": [
        "\n",
        "female_viq = data[data['Gender'] == 'Female']['VIQ']\n",
        "male_viq = data[data['Gender'] == 'Male']['VIQ']\n",
        "stats.ttest_ind(female_viq, male_viq) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opYcYwwYbY1-"
      },
      "source": [
        "## Paired tests: repeated measurements on the same individuals\n",
        "PIQ, VIQ, and FSIQ give 3 measures of IQ. Let us test if FISQ and PIQ are significantly different. We can use a 2 sample test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDlb7DkEa_Ug"
      },
      "source": [
        "stats.ttest_ind(data['FSIQ'], data['PIQ'])\n",
        "# try to use groupby to run a two-sample t-test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY_d308UbwUK"
      },
      "source": [
        "The problem with this approach is that it forgets that there are links between observations: FSIQ and PIQ are measured on the same individuals. Thus the variance due to inter-subject variability is confounding, and can be removed, using a “paired test”, or “repeated measures test”:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nybrm5VTbQpO"
      },
      "source": [
        "stats.ttest_rel(data['FSIQ'], data['PIQ']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLtSe0_scTBk"
      },
      "source": [
        "This is equivalent to a 1-sample test on the difference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBrbVyv0bX2V"
      },
      "source": [
        "stats.ttest_1samp(data['FSIQ'] - data['PIQ'], 0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xn-ouDNcYA1"
      },
      "source": [
        "T-tests assume Gaussian errors. We can use a Wilcoxon signed-rank test, that relaxes this assumption. Note The corresponding test in the non paired case is the Mann–Whitney U test, scipy.stats.mannwhitneyu()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UWA7AzzcXNI"
      },
      "source": [
        "stats.wilcoxon(data['FSIQ'], data['PIQ'])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkiaiiqTcs2N"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Test the difference between weights in males and females.\n",
        "Use non parametric statistics to test the difference between VIQ in males and females.\n",
        "Conclusion: we find that the data does not support the hypothesis that males and females have different VIQ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ9McOP0czi0"
      },
      "source": [
        "# Linear models, multiple factors, and analysis of variance\n",
        "Given two set of observations, x and y, we want to test the hypothesis that y is a linear function of x. In other terms:\n",
        "\n",
        "> y = ax + b + e\n",
        "\n",
        "where e is observation noise. We will use the statsmodels module to:\n",
        "\n",
        "Fit a linear model. We will use the simplest strategy, ordinary least squares (OLS).\n",
        "Test that coef is non zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-H_pqIEcnDo"
      },
      "source": [
        "x = np.linspace(-5, 5, 20)\n",
        "np.random.seed(1)\n",
        "# normal distributed noise\n",
        "y = -5 + 3*x + 4 * np.random.normal(size=x.shape)\n",
        "# Create a data frame containing all the relevant variables\n",
        "data = pd.DataFrame({'x': x, 'y': y})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecqvySgdmHq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOuOGkQMdjIz"
      },
      "source": [
        "from statsmodels.formula.api import ols\n",
        "model = ols(\"y ~ x\", data).fit()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWslokQ4mrd6"
      },
      "source": [
        "## Categorical variables:\n",
        " comparing groups or multiple categories\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81HPs71YmqfZ"
      },
      "source": [
        "data = pd.read_csv('https://scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values=\".\")\n",
        "model = ols(\"VIQ ~ Gender + 1\", data).fit()\n",
        "print(model.summary())  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWX588mpnIez"
      },
      "source": [
        "\n",
        "## Link to t-tests between different FSIQ and PIQ\n",
        "\n",
        "To compare different types of IQ, we need to create a “long-form” table, listing IQs, where the type of IQ is indicated by a categorical variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiuWkDTPnHny"
      },
      "source": [
        "data_fisq = pd.DataFrame({'iq': data['FSIQ'], 'type': 'fsiq'})\n",
        "data_piq = pd.DataFrame({'iq': data['PIQ'], 'type': 'piq'})\n",
        "data_long = pd.concat((data_fisq, data_piq))\n",
        "print(data_long)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85zfO1j_nZuQ"
      },
      "source": [
        "model = ols(\"iq ~ type\", data_long).fit()\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bizizr1OndAv"
      },
      "source": [
        "## Multiple Regression: \n",
        "including multiple factors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApeDiDzgnctM"
      },
      "source": [
        "data = pd.read_csv('https://scipy-lectures.org/_downloads/iris.csv')\n",
        "model = ols('sepal_width ~ name + petal_length', data).fit()\n",
        "print(model.summary())  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7VmJAkzoDy9"
      },
      "source": [
        "# Analysis of variance (ANOVA)\n",
        "In the above iris example, we wish to test if the petal length is different between versicolor and virginica, after removing the effect of sepal width. This can be formulated as testing the difference between the coefficient associated to versicolor and virginica in the linear model estimated above (it is an Analysis of Variance, ANOVA). For this, we write a vector of ‘contrast’ on the parameters estimated: we want to test \"name[T.versicolor] - name[T.virginica]\", with an F-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iix02Vn9oqZd"
      },
      "source": [
        "print(model.f_test([0, 1, -1, 0]))  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}